{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autores:\n",
    "- Adniel Quintana Muñoz\n",
    "- Carlos Cesar Caballero Díaz\n",
    "- Marisleydis Alvarez Noy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Informalmente el valor de la integral de una función $f(x)$ en el intervalo [a, b] es igual al área de la región limitada por la curva de $f(x)$, el eje $x$, y las rectas verticales $x = a$ y $x = b$. Esta área puede aproximarse mediante la suma de las áreas de los $n$ rectángulos:\n",
    "\n",
    "\\begin{align}\n",
    "\\int_a^b f(x)dx \\cong h \\sum_{j=0}^{n-1} f(x_j)\n",
    "\\end{align}\n",
    "\n",
    "donde $h = (b − a)/n$ es el paso de integración, $n$ es el número de sub-intervalos de integración, $yx_j = a + jh$ para $j = 0,1, ... , n − 1$ son los puntos dentro del intervalo de integración.\n",
    "\n",
    "Para el desarrollo del presente trabajo se implementaron en el lenguaje de programación Python en su versión 3.7.5, un algoritmo secuencial, y dos algoritmos paralelos utilizando multiprocessing y mpi4py, con el objetivo de analizar los resultados. Los experimentos se ejecutaron en un equipo con un procesador Intel® Core™ i7-8550U CPU @ 1.80GHz × 8 y 15,4 GiB de memoria ram disponibles sobre el sistema operativo Ubuntu en su versión 19.10. Los algoritmos paralelos se ejecutaron utilizando 4 núcleos de procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo\n",
    "\n",
    "Para el desarrollo del trabajo se realizaron tres implementaciones, una secuencial, una paralela en memoria utilizando el modulo multiprocessing (equivalente a OpenMP para Python) de la biblioteca estándar y otra implementación paralela utilizando el módulo mpi4py, el cual implementa MPI para este lenguaje de programación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integración secuencial\n",
    "\n",
    "Para la ejecución secuencial se implementó el algoritmo de integración numérica descrito en el ejercicio de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secuential_integrate(a,b,n,func):\n",
    "    #se calcula el ancho\n",
    "    h = (b-a)/n\n",
    "    i = 0.0\n",
    "    # se evalúa la función para cada uno de los fragmentos y se suman los resultados\n",
    "    for j in range(n):\n",
    "        i = i + func(a+j*h)\n",
    "    # los resultados de la ecaluación de la función se multiplican por h para obtener el valor de la integral\n",
    "    i = i*h\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo calcula el valor de la integral para la función `func` en el intervalo comprendido entre `a` y `b` para `n` rectángulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integración paralela\n",
    "\n",
    "Para la implementación paralela del algoritmo de integración en primer lugar se realizó una división del problema en partes de forma tal que se pudieran distribuir a múltiples tareas para que puedan trabajar en el problema simultáneamente mediante una descomposición de dominio en forma de bloques de una dimensión.\n",
    "\n",
    "Se elije realizar una descomposición de dominio porque es posible dividir el problema en partes iguales que realicen las mismas tareas (o pedazos de una misma tarea) en distintos núcleos de procesamiento.\n",
    "\n",
    "\n",
    "\n",
    "![title](assets/integral-parallel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing (equivalente a OpenMP)\n",
    "\n",
    "Para la ejecución paralela con multiprocessing (equivalente a OpenMP para el lenguaje de programación Python) se implementó el algoritmo de integración numérica descrito en el ejercicio de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_func = None\n",
    "\n",
    "def multiprocessing_integral(a, h, n, rank):\n",
    "    integ = 0.0\n",
    "    for j in range(n):\n",
    "        a_j = a + (j+n*rank) * h\n",
    "        integ += _func(a_j)\n",
    "    return integ\n",
    "\n",
    "\n",
    "def multiprocessing_integrate(a, b, n, func):\n",
    "    # la asignación de _func permitirá usar la lambda func con multiprocessing\n",
    "    global _func\n",
    "    _func = func\n",
    "\n",
    "    # size define la cantidad de procesos a ejecutar\n",
    "    size = 4\n",
    "    \n",
    "    # se divide n segun size\n",
    "    n = n//size\n",
    "    #se calcula el ancho\n",
    "    h = (b - a) / (n * size)\n",
    "\n",
    "    integral_values = []\n",
    "    # se declara un Pool para 'size' procesos\n",
    "    with Pool(size) as p:\n",
    "        # se instancia una funcion parcial para permitir multiples argumentos a multiprocessing \n",
    "        func = partial(multiprocessing_integral, a, h, n)\n",
    "        # se ejecutan los procesos y se espera por los resultados\n",
    "        integral_values = p.map(func, range(size))\n",
    "    integral_sum = 0.0\n",
    "    #se suman los resultados y se multiplica por h\n",
    "    for integral_value in integral_values:\n",
    "        integral_sum += integral_value\n",
    "    integral_sum = integral_sum * h\n",
    "    return integral_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPI (mpi4py)\n",
    "\n",
    "Para la ejecución paralela con MPI se implementó el algoritmo de integración numérica descrito en el ejercicio de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpi_integrate(a, b, n, func):\n",
    "    # se obtiene el intracommunicator COMM_WORLD\n",
    "    comm = MPI.COMM_WORLD\n",
    "    # se obtiene el proceso actual\n",
    "    rank = comm.Get_rank()\n",
    "    # se obtiene el total de procesos\n",
    "    size = comm.Get_size()\n",
    "\n",
    "    # se divide n segun size\n",
    "    n = n//size\n",
    "\n",
    "    def integral(a, h, n):\n",
    "        integ = 0.0\n",
    "        for j in range(n):\n",
    "            a_j = a + (j+n*rank) * h\n",
    "            integ += func(a_j)\n",
    "        return integ\n",
    "\n",
    "    #se calcula el ancho\n",
    "    h = (b - a) / (n * size)\n",
    "\n",
    "    # se calcula la integral para el proceso actual\n",
    "    my_int = numpy.full(1, integral(a, h, n))\n",
    "\n",
    "    \n",
    "    if rank == 0:\n",
    "        # si es el proceso 0, se dispone a obtener los datos de los otros procesos \n",
    "        integral_sum = my_int[0]\n",
    "        # ciclo en el que se obtienen los datos de los otros procesos y se termina el calculo de la integral\n",
    "        for p in range(1, size):\n",
    "            comm.Recv(my_int, source=p)\n",
    "            integral_sum += my_int[0]\n",
    "        integral_sum = integral_sum * h\n",
    "\n",
    "        print(integral_sum)\n",
    "    else:\n",
    "        # si no es el proceso 0, evía el resultado al proceso 0\n",
    "        comm.Send(my_int, dest=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución\n",
    "\n",
    "Para la ejecución del experimento se conformó un script en bash el cual realiza diez (10) ejecuciones para cada uno de los casos de pruebas definidos, en cuya salida se pueden obtener los siguientes valores:\n",
    "\n",
    "- mem: Porciento de memoria del sistema utilizada por la ejecución\n",
    "- RSS: Máxima memoria utilizada durante la ejecución\n",
    "- time: tiempo de ejecución\n",
    "- cpu.sys: Número total de segundos-CPU utilizados\n",
    "\n",
    "Para las funciones:\n",
    "\n",
    "- 1: $f(x) = x^2+cos(x)$\n",
    "- 2: $f(x) = (8*e^{(1-x)})+(7*log(x))$\n",
    "- 3: $f(x) = 10+x^2-10*cos^2(\\pi*x)^2$\n",
    "\n",
    "Arrojando el siguiente resultado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Función 1, n=10000\n",
    "\n",
    "    ---- secuencial -----\n",
    "    mem=0 RSS=37796 time=0:06.16 cpu.sys=5.13\n",
    "\n",
    "    ---- mpi -----\n",
    "    mem=0 RSS=38172 time=0:07.44 cpu.sys=8.33\n",
    "\n",
    "    ---- multiprocessing -----\n",
    "    mem=0 RSS=38672 time=0:07.34 cpu.sys=5.21\n",
    "    -------------------------------\n",
    "\n",
    "    Función 1, n=100000\n",
    "\n",
    "    ---- secuencial -----\n",
    "    mem=0 RSS=37684 time=0:06.61 cpu.sys=4.96\n",
    "\n",
    "    ---- mpi -----\n",
    "    mem=0 RSS=38296 time=0:07.49 cpu.sys=8.31\n",
    "\n",
    "    ---- multiprocessing -----\n",
    "    mem=0 RSS=38632 time=0:07.33 cpu.sys=5.39\n",
    "    -------------------------------\n",
    "\n",
    "    Función 1, n=1000000\n",
    "\n",
    "    ---- secuencial -----\n",
    "    mem=0 RSS=37740 time=0:10.62 cpu.sys=4.96\n",
    "\n",
    "    ---- mpi -----\n",
    "    mem=0 RSS=38276 time=0:08.96 cpu.sys=8.00\n",
    "\n",
    "    ---- multiprocessing -----\n",
    "    mem=0 RSS=38680 time=0:08.41 cpu.sys=5.44\n",
    "    -------------------------------\n",
    "\n",
    "    Función 2, n=10000\n",
    "\n",
    "    ---- secuencial -----\n",
    "    mem=0 RSS=37708 time=0:06.13 cpu.sys=4.95\n",
    "\n",
    "    ---- mpi -----\n",
    "    mem=0 RSS=38184 time=0:07.49 cpu.sys=8.23\n",
    "\n",
    "    ---- multiprocessing -----\n",
    "    mem=0 RSS=38796 time=0:07.34 cpu.sys=5.27\n",
    "    -------------------------------\n",
    "\n",
    "    Función 2, n=100000\n",
    "\n",
    "    ---- secuencial -----\n",
    "    mem=0 RSS=37768 time=0:06.80 cpu.sys=5.03\n",
    "\n",
    "    ---- mpi -----\n",
    "    mem=0 RSS=38124 time=0:07.80 cpu.sys=8.50\n",
    "\n",
    "    ---- multiprocessing -----\n",
    "    mem=0 RSS=38748 time=0:07.30 cpu.sys=5.36\n",
    "    -------------------------------\n",
    "\n",
    "    Función 2, n=1000000\n",
    "\n",
    "    ---- secuencial -----\n",
    "    mem=0 RSS=37696 time=0:13.07 cpu.sys=4.96\n",
    "\n",
    "    ---- mpi -----\n",
    "    mem=0 RSS=38196 time=0:09.55 cpu.sys=8.29\n",
    "\n",
    "    ---- multiprocessing -----\n",
    "    mem=0 RSS=38760 time=0:09.30 cpu.sys=5.24\n",
    "    -------------------------------\n",
    "\n",
    "    Función 3, n=10000\n",
    "\n",
    "    ---- secuencial -----\n",
    "    mem=0 RSS=37764 time=0:06.17 cpu.sys=5.18\n",
    "\n",
    "    ---- mpi -----\n",
    "    mem=0 RSS=38204 time=0:07.62 cpu.sys=8.23\n",
    "\n",
    "    ---- multiprocessing -----\n",
    "    mem=0 RSS=38828 time=0:07.34 cpu.sys=5.24\n",
    "    -------------------------------\n",
    "\n",
    "    Función 3, n=100000\n",
    "\n",
    "    ---- secuencial -----\n",
    "    mem=0 RSS=37740 time=0:06.80 cpu.sys=4.87\n",
    "\n",
    "    ---- mpi -----\n",
    "    mem=0 RSS=38308 time=0:07.78 cpu.sys=8.58\n",
    "\n",
    "    ---- multiprocessing -----\n",
    "    mem=0 RSS=38576 time=0:07.36 cpu.sys=5.17\n",
    "    -------------------------------\n",
    "\n",
    "    Función 3, n=1000000\n",
    "\n",
    "    ---- secuencial -----\n",
    "    mem=0 RSS=37816 time=0:13.23 cpu.sys=5.09\n",
    "\n",
    "    ---- mpi -----\n",
    "    mem=0 RSS=38292 time=0:09.65 cpu.sys=8.43\n",
    "\n",
    "    ---- multiprocessing -----\n",
    "    mem=0 RSS=38756 time=0:09.61 cpu.sys=5.43\n",
    "    -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "Tras los resultados experimentales se puede concluir que, para resultados con `n=10000` el algoritmo secuencial presenta menores tiempos de ejecución, seguido de la implementación con multiprocesing y luego MPI. Para los resultados con `n=100000` el algoritmo secuencial continúa presentando menores tiempos de ejecución aunque con una menor diferencia con respecto a la implementación utilizando multiprocessing y continuando la implementación MPI con los mayores tiempos de ejecución. Para los resultados con `n=1000000` se comienzan a ver las ventajas de la implementación paralela, teniendo multiprocessing los menores tiempos de ejecución, seguido por MPI, ambos presentando diferencias notables con respecto a la implementación secuencial.\n",
    "\n",
    "El comportamiento en cuanto al consumo de memoria se aprecia de forma similar en las distintas ejecuciones, presentando la implementación secuencial un menor consumo de memoria, seguido de la implementación MPI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anexos\n",
    "\n",
    "- implementación: https://github.com/cccaballero/miav-programacion-avanzada"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
